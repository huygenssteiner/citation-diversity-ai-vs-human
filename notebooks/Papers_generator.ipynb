{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c008e5-c67b-4c63-ab3a-02d2e50cc430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import FineGrainedFP8Config, AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# Set the PyTorch CUDA configuration for memory management\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(\"\") #Insert your huggingface token to import the model\n",
    "\n",
    "# Determine the device (ensure you have an H100 GPU or similar for FP8 support)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device in use: {device}\")\n",
    "\n",
    "# Load the 70B LLaMA model in FP8 precision\n",
    "#model_id = \"CohereLabs/aya-expanse-32b\"\n",
    "#model_id = \"RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic\"\n",
    "#model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\"\n",
    "#model_id = \"mistralai/Mistral-Small-3.1-24B-Instruct-2503\"\n",
    "model_id = \"Qwen/Qwen3-32B\"\n",
    "#model_id = \"google/gemma-3-27b-it\"\n",
    "# Define the FP8 quantization configuration\n",
    "#quantization_config = FineGrainedFP8Config()\n",
    "\n",
    "# Load the model with FP8 quantization\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=\"auto\",  # Automatically uses the model's default dtype\n",
    "    device_map=\"cuda\",   # Automatically maps the model across available GPUs\n",
    "    #quantization_config=quantization_config  # Apply FP8 quantization\n",
    ")\n",
    "# Load tokenizer for LLaMA models\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac3006d-56bd-488e-8d98-a1c88d23c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chatbot_without_memory(prompt, temperature=0.7, max_new_tokens=32768, thinking=False, stop_token=\"\"):\n",
    "    \"\"\"\n",
    "    Generates a response from the language model without memory between turns.\n",
    "    Optionally enables the model's internal 'thinking' mode, separating reasoning from final output.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    prompt : str\n",
    "        The input prompt or user message.\n",
    "    temperature : float, default=0.7\n",
    "        Controls randomness in generation (higher = more diverse/creative responses).\n",
    "    max_new_tokens : int, default=32768\n",
    "        Maximum number of tokens to generate.\n",
    "    thinking : bool, default=False\n",
    "        Whether to activate Qwen2.5's internal 'thinking mode', which separates reasoning (`<think>...</think>`) \n",
    "        from the final response.\n",
    "    stop_token : str, default=\"\"\n",
    "        If specified, the final output will be truncated at this token.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    content : str\n",
    "        The final assistant reply (content after the `</think>` token, or full output if `thinking=False`).\n",
    "    \"\"\"\n",
    "\n",
    "    # Create chat-style input\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    formatted_prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=thinking  # Enable Qwen's thinking mode\n",
    "    )\n",
    "\n",
    "    # Tokenize\n",
    "    model_inputs = tokenizer([formatted_prompt], return_tensors=\"pt\").to(model.device)\n",
    "        # Generate output\n",
    "    generation_args = dict(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    generation_args.update({ \n",
    "            \"top_p\": 0.8,\n",
    "            \"top_k\": 20,\n",
    "            \"min_p\": 0.0\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "    generated_ids = model.generate(**generation_args)\n",
    "\n",
    "\n",
    "    # Extract newly generated token ids\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "    # Parse thinking content\n",
    "    try:\n",
    "        # 151668 corresponds to </think> token id in Qwen2.5\n",
    "        think_token_id = 151668\n",
    "        index = len(output_ids) - output_ids[::-1].index(think_token_id)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "\n",
    "    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "    # Optionally truncate at stop_token\n",
    "    if stop_token and stop_token in content:\n",
    "        content = content.split(stop_token)[0].strip()\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f849be7-741f-4357-a026-5674cdbf68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"computer_science_up_to_2025_with_bibliography.csv\") #import the dataframe with the papers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a545e63-8641-402c-b43e-5ffa30d44014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "from collections import Counter, defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from rapidfuzz import fuzz\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "\n",
    "# --- Initialization ---\n",
    "gender_detector = gender.Detector()\n",
    "session = requests.Session()\n",
    "\n",
    "\n",
    "# =======================\n",
    "# PROMPT CREATION\n",
    "# =======================\n",
    "\n",
    "def create_prompt(title, abstract):\n",
    "    \"\"\"\n",
    "    Create a prompt to ask an LLM to generate a plausible bibliography.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "Generate a list of references for a paper having as title and abstract:\n",
    "\n",
    "Title: {title}\n",
    "\n",
    "Abstract: {abstract}\n",
    "\n",
    "Bibliography:\n",
    "\n",
    "Please format the bibliography as a numbered list, where each reference follows this pattern:\n",
    "Author(s): <authors>; Title: \"<title>\"; Year: <year>; Venue: <journal/conference>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# =======================\n",
    "# BIBLIOGRAPHY PARSING & NORMALIZATION\n",
    "# =======================\n",
    "\n",
    "def parse_structured_bibliography(bib_text):\n",
    "    \"\"\"\n",
    "    Parse a structured bibliography from formatted text.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'^\\d+\\.\\s*Author\\(s\\):\\s*(.+?);\\s*Title:\\s*\"(.+?)\";\\s*Year:\\s*(\\d{4});\\s*Venue:\\s*(.+)$')\n",
    "    parsed_refs = []\n",
    "    for line in bib_text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        m = pattern.match(line)\n",
    "        if m:\n",
    "            authors = [a.strip() for a in m.group(1).split(\",\") if a.strip()]\n",
    "            parsed_refs.append({\n",
    "                \"authors\": authors,\n",
    "                \"title\": m.group(2).strip(),\n",
    "                \"year\": int(m.group(3)),\n",
    "                \"venue\": m.group(4).strip()\n",
    "            })\n",
    "    return parsed_refs\n",
    "\n",
    "\n",
    "def normalize_title(title):\n",
    "    \"\"\"\n",
    "    Normalize a title string for comparison (case-folding, diacritics, punctuation).\n",
    "    \"\"\"\n",
    "    if not isinstance(title, str):\n",
    "        return \"\"\n",
    "    title = title.lower()\n",
    "    title = unicodedata.normalize('NFKD', title)\n",
    "    title = ''.join([c for c in title if not unicodedata.combining(c)])\n",
    "    title = re.sub(r'[^\\w\\s]', '', title)\n",
    "    title = re.sub(r'\\s+', ' ', title)\n",
    "    return title.strip()\n",
    "\n",
    "\n",
    "def normalize_safe(s):\n",
    "    return normalize_title(s) if isinstance(s, str) else \"\"\n",
    "\n",
    "\n",
    "def deduplicate_references(refs):\n",
    "    \"\"\"\n",
    "    Remove duplicate references based on normalized titles.\n",
    "    \"\"\"\n",
    "    seen_titles = set()\n",
    "    unique_refs = []\n",
    "    for ref in refs:\n",
    "        norm_title = normalize_title(ref.get('title', ''))\n",
    "        if norm_title not in seen_titles:\n",
    "            seen_titles.add(norm_title)\n",
    "            unique_refs.append(ref)\n",
    "    return unique_refs\n",
    "\n",
    "\n",
    "# =======================\n",
    "# OPENALEX API INTERACTION\n",
    "# =======================\n",
    "\n",
    "def get_bibliography_from_openalex(work_ids):\n",
    "    \"\"\"\n",
    "    Retrieve detailed bibliography info from OpenAlex given work IDs.\n",
    "    \"\"\"\n",
    "    bib = []\n",
    "    for wid in work_ids:\n",
    "        url = f\"https://api.openalex.org/works/{wid}\"\n",
    "        r = session.get(url)\n",
    "        if r.status_code != 200:\n",
    "            continue\n",
    "        data = r.json()\n",
    "        primary_location = data.get(\"primary_location\") or {}\n",
    "        bib.append({\n",
    "            \"title\": data.get(\"title\", \"Unknown Title\"),\n",
    "            \"authors\": [\n",
    "                {\"name\": a['author']['display_name'], \"id\": a['author'].get('id')}\n",
    "                for a in data.get(\"authorships\", []) if 'author' in a\n",
    "            ],\n",
    "            \"year\": data.get(\"publication_year\"),\n",
    "            \"venue\": primary_location.get(\"display_name\", \"Unknown Venue\"),\n",
    "            \"citation_count\": data.get(\"cited_by_count\", 0)\n",
    "        })\n",
    "    return bib\n",
    "\n",
    "\n",
    "def query_openalex_by_title(title):\n",
    "    \"\"\"\n",
    "    Search for a single paper in OpenAlex using its title.\n",
    "    \"\"\"\n",
    "    url = \"https://api.openalex.org/works\"\n",
    "    params = {\"search\": title, \"per-page\": 1}\n",
    "    r = session.get(url, params=params)\n",
    "    if r.status_code != 200 or not r.json().get('results'):\n",
    "        return None\n",
    "    work = r.json()['results'][0]\n",
    "    primary_location = work.get(\"primary_location\") or {}\n",
    "    source = primary_location.get(\"source\") or {}\n",
    "    venue = source.get(\"display_name\", \"Unknown Venue\")\n",
    "    return {\n",
    "        \"title\": work.get(\"title\"),\n",
    "        \"authors\": [\n",
    "            {\"name\": a['author']['display_name'], \"id\": a['author'].get('id')} \n",
    "            for a in work.get(\"authorships\", []) if 'author' in a\n",
    "        ],\n",
    "        \"year\": work.get(\"publication_year\"),\n",
    "        \"venue\": venue,\n",
    "        \"citation_count\": work.get(\"cited_by_count\", 0)\n",
    "    }\n",
    "\n",
    "\n",
    "def query_openalex_by_id(openalex_id):\n",
    "    \"\"\"\n",
    "    Fetch work metadata from OpenAlex by its ID.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.openalex.org/works/{openalex_id}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json() if response.status_code == 200 else None\n",
    "\n",
    "\n",
    "def search_openalex_by_title(title, top_k=10):\n",
    "    \"\"\"\n",
    "    Search OpenAlex for papers by title and return top candidates.\n",
    "    \"\"\"\n",
    "    query = title.replace('\"', '')\n",
    "    url = f\"https://api.openalex.org/works?search={requests.utils.quote(query)}&per-page={top_k}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json().get('results', []) if response.status_code == 200 else []\n",
    "\n",
    "\n",
    "def best_fuzzy_match_among_candidates(gen_title, candidates, threshold=85):\n",
    "    \"\"\"\n",
    "    Use fuzzy matching to find best match among OpenAlex candidates.\n",
    "    \"\"\"\n",
    "    best_score = 0\n",
    "    best_match = None\n",
    "    gen_title_l = normalize_title(gen_title)\n",
    "\n",
    "    for work in candidates:\n",
    "        real_title = work.get('title', '')\n",
    "        real_title_l = normalize_title(real_title)\n",
    "        score = max(\n",
    "            fuzz.ratio(gen_title_l, real_title_l),\n",
    "            fuzz.token_sort_ratio(gen_title_l, real_title_l),\n",
    "            fuzz.partial_ratio(gen_title_l, real_title_l)\n",
    "        )\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = work\n",
    "        if score >= threshold:\n",
    "            return True, score, best_match\n",
    "    return False, best_score, best_match\n",
    "\n",
    "\n",
    "def evaluate_hallucination_rate_via_openalex_search(generated_refs, threshold=85, top_k=10):\n",
    "    \"\"\"\n",
    "    Evaluate how many generated references are hallucinated by comparing to OpenAlex.\n",
    "    \"\"\"\n",
    "    non_hallucinated_refs = []\n",
    "    hallucinated_count = 0\n",
    "    diagnostics = []\n",
    "\n",
    "    for gen_ref in generated_refs:\n",
    "        gen_title = gen_ref.get('title', '')\n",
    "        candidates = search_openalex_by_title(gen_title, top_k=top_k)\n",
    "        match_found, best_score, best_match = best_fuzzy_match_among_candidates(\n",
    "            gen_title, candidates, threshold=threshold)\n",
    "        \n",
    "        diagnostics.append({\n",
    "            \"gen_title\": gen_title,\n",
    "            \"match_found\": match_found,\n",
    "            \"best_score\": best_score,\n",
    "            \"best_match_title\": best_match['title'] if best_match else None\n",
    "        })\n",
    "\n",
    "        if match_found:\n",
    "            non_hallucinated_refs.append(gen_ref)\n",
    "        else:\n",
    "            hallucinated_count += 1\n",
    "\n",
    "    hallucination_rate = hallucinated_count / len(generated_refs) if generated_refs else 0\n",
    "    return hallucinated_count > 0, hallucination_rate, non_hallucinated_refs, diagnostics\n",
    "\n",
    "\n",
    "# =======================\n",
    "# AUTHOR METADATA ENRICHMENT\n",
    "# =======================\n",
    "\n",
    "def extract_institution_and_country(authorship):\n",
    "    \"\"\"\n",
    "    Extract institution and country code from an authorship record.\n",
    "    \"\"\"\n",
    "    institution = None\n",
    "    country = None\n",
    "    if 'institutions' in authorship and authorship['institutions']:\n",
    "        for inst in authorship['institutions']:\n",
    "            country_code = inst.get('country_code')\n",
    "            if country_code:\n",
    "                institution = inst.get('display_name')\n",
    "                country = country_code\n",
    "                break\n",
    "        if not country:\n",
    "            institution = authorship['institutions'][0].get('display_name')\n",
    "    return institution, country\n",
    "\n",
    "\n",
    "def get_author_metadata(author_id):\n",
    "    \"\"\"\n",
    "    Retrieve gender and country info of an author by OpenAlex ID.\n",
    "    \"\"\"\n",
    "    works_url = \"https://api.openalex.org/works\"\n",
    "    params = {\n",
    "        \"filter\": f\"author.id:{author_id}\",\n",
    "        \"sort\": \"cited_by_count:desc\",\n",
    "        \"per-page\": 1\n",
    "    }\n",
    "    r = session.get(works_url, params=params)\n",
    "    if r.status_code != 200 or not r.json().get(\"results\"):\n",
    "        return None\n",
    "\n",
    "    work = r.json()['results'][0]\n",
    "    for authorship in work.get(\"authorships\", []):\n",
    "        author = authorship.get(\"author\", {})\n",
    "        if author.get(\"id\") == author_id:\n",
    "            name = author.get(\"display_name\", \"\")\n",
    "            first_name = name.split()[0] if name else \"\"\n",
    "            gender_raw = gender_detector.get_gender(first_name)\n",
    "            gender_simple = (\n",
    "                \"male\" if gender_raw in [\"male\", \"mostly_male\"]\n",
    "                else \"female\" if gender_raw in [\"female\", \"mostly_female\"]\n",
    "                else \"unknown\"\n",
    "            )\n",
    "            _, country = extract_institution_and_country(authorship)\n",
    "            return {\n",
    "                \"id\": author_id,\n",
    "                \"name\": name,\n",
    "                \"gender\": gender_simple,\n",
    "                \"country\": country or \"unknown\"\n",
    "            }\n",
    "    return None\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def enrich_bibliography_authors(bib, author_metadata_list):\n",
    "    \"\"\"Attach gender and country metadata to authors.\"\"\"\n",
    "    meta_by_id = {a['id']: a for a in author_metadata_list}\n",
    "    for ref in bib:\n",
    "        for author in ref.get(\"authors\", []):\n",
    "            author_id = author.get(\"id\")\n",
    "            if author_id and author_id in meta_by_id:\n",
    "                author.update({\n",
    "                    \"gender\": meta_by_id[author_id].get(\"gender\", \"unknown\"),\n",
    "                    \"country\": meta_by_id[author_id].get(\"country\", \"unknown\")\n",
    "                })\n",
    "\n",
    "\n",
    "def analyze_bibliography_with_authors(bib):\n",
    "    \"\"\"\n",
    "    Analyze reference list to get aggregate stats on year, venues, citations, gender, country.\n",
    "    \"\"\"\n",
    "    years = [ref['year'] for ref in bib if ref.get('year')]\n",
    "    venues = [ref['venue'] for ref in bib if ref.get('venue')]\n",
    "    citations = [ref.get('citation_count', 0) for ref in bib]\n",
    "    authors = [a for ref in bib for a in ref.get('authors', []) if 'name' in a and 'id' in a]\n",
    "    author_ids = {a['id'] for a in authors}\n",
    "    author_metadata_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(get_author_metadata, aid): aid for aid in author_ids}\n",
    "        for future in as_completed(futures):\n",
    "            author_meta = future.result()\n",
    "            if author_meta:\n",
    "                author_metadata_list.append(author_meta)\n",
    "\n",
    "    return {\n",
    "        \"num_references\": len(bib),\n",
    "        \"avg_year\": mean(years) if years else None,\n",
    "        \"venue_counts\": Counter(venues),\n",
    "        \"avg_citations\": mean(citations) if citations else None,\n",
    "        \"author_metadata\": author_metadata_list,\n",
    "        \"gender_distribution\": Counter(a['gender'] for a in author_metadata_list),\n",
    "        \"country_distribution\": Counter(a['country'] for a in author_metadata_list)\n",
    "    }\n",
    "\n",
    "\n",
    "# =======================\n",
    "# AGGREGATION\n",
    "# =======================\n",
    "\n",
    "def aggregate_stats(stats_list):\n",
    "    \"\"\"\n",
    "    Aggregate stats across multiple reference analyses.\n",
    "    \"\"\"\n",
    "    total_refs = sum(s[\"num_references\"] for s in stats_list)\n",
    "    avg_year = mean([s[\"avg_year\"] for s in stats_list if s[\"avg_year\"]])\n",
    "    avg_citations = mean([s[\"avg_citations\"] for s in stats_list if s[\"avg_citations\"]])\n",
    "\n",
    "    venue_counts = Counter()\n",
    "    gender_counts = Counter()\n",
    "    country_counts = Counter()\n",
    "    for s in stats_list:\n",
    "        venue_counts.update(s[\"venue_counts\"])\n",
    "        gender_counts.update(s[\"gender_distribution\"])\n",
    "        country_counts.update(s[\"country_distribution\"])\n",
    "\n",
    "    return {\n",
    "        \"num_references\": total_refs,\n",
    "        \"avg_year\": avg_year,\n",
    "        \"avg_citations\": avg_citations,\n",
    "        \"venue_counts\": venue_counts,\n",
    "        \"gender_distribution\": gender_counts,\n",
    "        \"country_distribution\": country_counts\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def print_stats(label, stats):\n",
    "    \"\"\"Print analysis statistics in a readable format.\"\"\"\n",
    "    print(f\"===== {label} =====\")\n",
    "    print(f\"Total number of references: {stats['num_references']}\")\n",
    "    print(f\"Average publication year: {stats['avg_year']:.1f}\" if stats['avg_year'] else \"N/A\")\n",
    "    print(f\"Average citation count: {stats['avg_citations']:.1f}\" if stats['avg_citations'] else \"N/A\")\n",
    "    print(\"Top venues:\", stats['venue_counts'].most_common(10))\n",
    "    print(\"Top authors:\", stats['author_counts'].most_common(10))\n",
    "    print(\"Gender distribution:\", dict(stats['gender_distribution']))\n",
    "    print(\"Top countries:\", stats['country_distribution'].most_common(10))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e268cf05-49fd-49f2-b3bb-dacb5d024527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "# === EXPLANATION ===\n",
    "# This pipeline compares real vs. LLM-generated bibliographies from paper abstracts.\n",
    "# 1. It generates a bibliography using a language model.\n",
    "# 2. Fetches metadata for both real and generated references from OpenAlex.\n",
    "# 3. Analyzes gender, country, citation stats, etc.\n",
    "# 4. Evaluates hallucinations in the LLM output.\n",
    "# 5. Saves detailed results and summary statistics for further study.\n",
    "\n",
    "\n",
    "\n",
    "# Output file paths\n",
    "results_jsonl_path = f\"results/full_bibliography_metadata_{model_id}.jsonl\"\n",
    "summary_csv_path = f\"results/bibliography_summary_{model_id}.csv\"\n",
    "os.makedirs(os.path.dirname(results_jsonl_path), exist_ok=True)\n",
    "\n",
    "\n",
    "# --- Load already processed paper IDs to skip duplicates ---\n",
    "processed_ids = set()\n",
    "if os.path.exists(results_jsonl_path):\n",
    "    with open(results_jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                entry = json.loads(line)\n",
    "                processed_ids.add(entry[\"paper_id\"])\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "results = []\n",
    "start = 0\n",
    "end = 100\n",
    "\n",
    "# --- Main Loop over the dataset ---\n",
    "for i, row in tqdm(df.iloc[start:end].iterrows(), total=end - start):\n",
    "    paper_id = i\n",
    "    if paper_id in processed_ids:\n",
    "        continue\n",
    "\n",
    "    title, abstract, ref_ids = row['title'], row['abstract'], row['referenced_works']\n",
    "    if not ref_ids:\n",
    "        continue\n",
    "\n",
    "    # === STEP 1: GENERATE BIBLIOGRAPHY ===\n",
    "    prompt = create_prompt(title, abstract)\n",
    "    generated_bib_text = create_chatbot_without_memory(prompt, temperature=0.7, thinking=False)\n",
    "    generated_refs = deduplicate_references(parse_structured_bibliography(generated_bib_text))\n",
    "\n",
    "    # === STEP 2: FETCH METADATA FOR GENERATED REFERENCES ===\n",
    "    generated_bib = []\n",
    "    seen_titles = set()\n",
    "    for ref in generated_refs:\n",
    "        if ref['title'] in seen_titles:\n",
    "            continue\n",
    "        meta = query_openalex_by_title(ref['title'])\n",
    "        if meta:\n",
    "            generated_bib.append(meta)\n",
    "            seen_titles.add(ref['title'])\n",
    "\n",
    "    # === STEP 3: FETCH METADATA FOR REAL REFERENCES ===\n",
    "    real_titles = []\n",
    "    for openalex_id in ref_ids.split(\"; \"):\n",
    "        meta = query_openalex_by_id(openalex_id)\n",
    "        if meta and 'title' in meta:\n",
    "            real_titles.append(meta['title'])\n",
    "\n",
    "    real_bib = []\n",
    "    seen_titles = set()\n",
    "    for real_title in real_titles:\n",
    "        if real_title in seen_titles:\n",
    "            continue\n",
    "        meta = query_openalex_by_title(real_title)\n",
    "        if meta:\n",
    "            real_bib.append(meta)\n",
    "            seen_titles.add(real_title)\n",
    "\n",
    "    # === STEP 4: ANALYZE BOTH BIBLIOGRAPHIES ===\n",
    "    real_stats = analyze_bibliography_with_authors(real_bib)\n",
    "    gen_stats = analyze_bibliography_with_authors(generated_bib)\n",
    "    enrich_bibliography_authors(real_bib, real_stats['author_metadata'])\n",
    "    enrich_bibliography_authors(generated_bib, gen_stats['author_metadata'])\n",
    "\n",
    "    # === STEP 5: EVALUATE HALLUCINATIONS ===\n",
    "    hallucination_detected, hallucination_rate, filtered_generated_refs, diagnostics = \\\n",
    "        evaluate_hallucination_rate_via_openalex_search(generated_refs, threshold=85)\n",
    "\n",
    "    # Rebuild filtered generated bibliography\n",
    "    generated_bib = []\n",
    "    seen_titles = set()\n",
    "    for ref in filtered_generated_refs:\n",
    "        if ref['title'] in seen_titles:\n",
    "            continue\n",
    "        meta = query_openalex_by_title(ref['title'])\n",
    "        if meta:\n",
    "            generated_bib.append(meta)\n",
    "            seen_titles.add(ref['title'])\n",
    "\n",
    "    # === STEP 6: SAVE FULL METADATA JSONL ===\n",
    "    result = {\n",
    "        \"paper_id\": paper_id,\n",
    "        \"title\": title,\n",
    "        \"hallucination_detected\": hallucination_detected,\n",
    "        \"hallucination_rate\": hallucination_rate,\n",
    "        \"real_bibliography\": real_bib,\n",
    "        \"generated_bibliography\": generated_bib,\n",
    "        \"real_analysis\": real_stats,\n",
    "        \"generated_analysis\": gen_stats,\n",
    "    }\n",
    "    with open(results_jsonl_path, \"a\", encoding=\"utf-8\") as f_jsonl:\n",
    "        f_jsonl.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    # === STEP 7: SAVE SUMMARY TO CSV ===\n",
    "    summary_row = {\n",
    "        \"paper_id\": paper_id,\n",
    "        \"title\": title,\n",
    "        \"num_refs_real\": real_stats[\"num_references\"],\n",
    "        \"num_refs_gen\": gen_stats[\"num_references\"],\n",
    "        \"avg_year_real\": real_stats[\"avg_year\"],\n",
    "        \"avg_year_gen\": gen_stats[\"avg_year\"],\n",
    "        \"avg_citations_real\": real_stats[\"avg_citations\"],\n",
    "        \"avg_citations_gen\": gen_stats[\"avg_citations\"],\n",
    "        \"gender_male_real\": real_stats[\"gender_distribution\"].get(\"male\", 0),\n",
    "        \"gender_female_real\": real_stats[\"gender_distribution\"].get(\"female\", 0),\n",
    "        \"gender_unknown_real\": real_stats[\"gender_distribution\"].get(\"unknown\", 0),\n",
    "        \"gender_male_gen\": gen_stats[\"gender_distribution\"].get(\"male\", 0),\n",
    "        \"gender_female_gen\": gen_stats[\"gender_distribution\"].get(\"female\", 0),\n",
    "        \"gender_unknown_gen\": gen_stats[\"gender_distribution\"].get(\"unknown\", 0),\n",
    "        \"top_country_real\": real_stats[\"country_distribution\"].most_common(1)[0][0] if real_stats[\"country_distribution\"] else None,\n",
    "        \"top_country_gen\": gen_stats[\"country_distribution\"].most_common(1)[0][0] if gen_stats[\"country_distribution\"] else None,\n",
    "    }\n",
    "\n",
    "    df_summary = pd.DataFrame([summary_row])\n",
    "    write_header = not os.path.exists(summary_csv_path)\n",
    "    os.makedirs(os.path.dirname(summary_csv_path), exist_ok=True)\n",
    "    df_summary.to_csv(summary_csv_path, mode=\"a\", index=False, header=write_header)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

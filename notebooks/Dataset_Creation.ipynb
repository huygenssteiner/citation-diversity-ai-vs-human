{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9bd83-fafa-4570-bdb4-f979f9eed31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def get_field_id(field_name):\n",
    "    \"\"\"\n",
    "    Query OpenAlex API to find the concept ID corresponding to a given field name.\n",
    "    This ID is used to filter papers by field.\n",
    "    \n",
    "    Args:\n",
    "        field_name (str): Name of the research field (e.g., 'computer science').\n",
    "    \n",
    "    Returns:\n",
    "        str: OpenAlex concept ID for the field.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the field name is not found in OpenAlex concepts.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.openalex.org/concepts?search={field_name}&per-page=1\"\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    results = r.json()['results']\n",
    "    if results:\n",
    "        return results[0]['id']\n",
    "    else:\n",
    "        raise ValueError(f\"Field '{field_name}' not found.\")\n",
    "\n",
    "def invert_abstract_index(inverted_index):\n",
    "    \"\"\"\n",
    "    Reconstruct plain-text abstract from OpenAlex inverted index format.\n",
    "    The inverted index is a dict mapping words to positions.\n",
    "    \n",
    "    Args:\n",
    "        inverted_index (dict): e.g. {'word': [positions]}\n",
    "        \n",
    "    Returns:\n",
    "        str: The reconstructed abstract as plain text.\n",
    "    \"\"\"\n",
    "    position_word_pairs = []\n",
    "    # Build a list of (position, word) tuples for sorting\n",
    "    for word, positions in inverted_index.items():\n",
    "        for pos in positions:\n",
    "            position_word_pairs.append((pos, word))\n",
    "    # Sort by position to reconstruct original order\n",
    "    position_word_pairs.sort(key=lambda x: x[0])\n",
    "    words = [w for _, w in position_word_pairs]\n",
    "    # Join all words with space to form the abstract text\n",
    "    return \" \".join(words)\n",
    "\n",
    "def fetch_papers_up_to_year(field_id, max_year, min_year=1800, max_results=1000):\n",
    "    \"\"\"\n",
    "    Fetch papers from OpenAlex API filtered by field ID and publication years descending\n",
    "    from max_year down to min_year, stopping when max_results are reached.\n",
    "    \n",
    "    Uses cursor-based pagination and requests up to 200 papers per page.\n",
    "    \n",
    "    Args:\n",
    "        field_id (str): OpenAlex concept ID for filtering.\n",
    "        max_year (int): Latest publication year to include.\n",
    "        min_year (int): Earliest publication year to include (default 1800).\n",
    "        max_results (int): Maximum number of papers to fetch (default 1000).\n",
    "        \n",
    "    Returns:\n",
    "        list: List of paper metadata dicts.\n",
    "    \"\"\"\n",
    "    url = \"https://api.openalex.org/works\"\n",
    "    papers = []\n",
    "    count = 0\n",
    "\n",
    "    # Loop over years descending: newest to oldest\n",
    "    for year in range(max_year, min_year - 1, -1):\n",
    "        if count >= max_results:\n",
    "            break\n",
    "\n",
    "        print(f\"Fetching papers for year {year}... {count}/{max_results}\")\n",
    "        # Initial params: filter by field and year, 200 results per page, start cursor\n",
    "        params = {\n",
    "            \"filter\": f\"concepts.id:{field_id},publication_year:{year}\",\n",
    "            \"per-page\": 200,\n",
    "            \"cursor\": \"*\"\n",
    "        }\n",
    "\n",
    "        while count < max_results:\n",
    "            r = requests.get(url, params=params)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            results = data['results']\n",
    "            if not results:\n",
    "                # No more results for this year\n",
    "                break\n",
    "\n",
    "            papers.extend(results)\n",
    "            count += len(results)\n",
    "            if count >= max_results:\n",
    "                # Reached maximum papers to fetch\n",
    "                break\n",
    "\n",
    "            # Pagination: get the next cursor to fetch next page\n",
    "            next_cursor = data.get('meta', {}).get('next_cursor')\n",
    "            if not next_cursor:\n",
    "                # No more pages\n",
    "                break\n",
    "\n",
    "            params[\"cursor\"] = next_cursor\n",
    "            time.sleep(1)  # Rate limiting pause to avoid hitting API limits\n",
    "\n",
    "    return papers[:max_results]\n",
    "\n",
    "def extract_institution_and_country(authorship):\n",
    "    \"\"\"\n",
    "    Extract the first institution's name and country code from an authorship record.\n",
    "    \n",
    "    Args:\n",
    "        authorship (dict): Single authorship entry from OpenAlex paper data.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (institution_name (str or None), country_code (str or None))\n",
    "    \"\"\"\n",
    "    institution = None\n",
    "    country = None\n",
    "    if 'institutions' in authorship and authorship['institutions']:\n",
    "        inst = authorship['institutions'][0]  # Take first institution only\n",
    "        institution = inst.get('display_name')\n",
    "        country = inst.get('country_code')\n",
    "    return institution, country\n",
    "\n",
    "def save_papers_to_csv(papers, filename):\n",
    "    \"\"\"\n",
    "    Process raw paper data, filter papers without abstracts, bibliographies, or country data,\n",
    "    reconstruct abstracts from inverted index if necessary, and save to CSV.\n",
    "    \n",
    "    Args:\n",
    "        papers (list): List of paper metadata dicts.\n",
    "        filename (str): Output CSV filename.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for paper in papers:\n",
    "        # Reconstruct abstract text if inverted index present, else use plain abstract field\n",
    "        abstract_inverted = paper.get('abstract_inverted_index', None)\n",
    "        abstract = invert_abstract_index(abstract_inverted) if abstract_inverted else paper.get('abstract')\n",
    "\n",
    "        if not abstract or not abstract.strip():\n",
    "            # Skip papers without abstract text\n",
    "            continue\n",
    "\n",
    "        # Extract bibliography references (list of paper IDs)\n",
    "        referenced_works = paper.get('referenced_works', [])\n",
    "        if not referenced_works:\n",
    "            # Skip papers without bibliography\n",
    "            continue\n",
    "\n",
    "        # Extract authorship info: names, institutions, countries\n",
    "        authors_list = []\n",
    "        institutions_list = []\n",
    "        countries_list = []\n",
    "        for authorship in paper.get('authorships', []):\n",
    "            author_name = authorship.get('author', {}).get('display_name') if 'author' in authorship else None\n",
    "            institution, country = extract_institution_and_country(authorship)\n",
    "            authors_list.append(author_name)\n",
    "            institutions_list.append(institution)\n",
    "            countries_list.append(country)\n",
    "\n",
    "        # Filter out papers where all authors have no country info\n",
    "        if all(c is None for c in countries_list):\n",
    "            continue\n",
    "\n",
    "        # Extract concepts (fields of study) as a semicolon-separated string\n",
    "        concepts = [concept['display_name'] for concept in paper.get('concepts', [])]\n",
    "\n",
    "        # Append processed record to list\n",
    "        records.append({\n",
    "            \"id\": paper.get('id'),\n",
    "            \"title\": paper.get('title'),\n",
    "            \"doi\": paper.get('doi'),\n",
    "            \"publication_year\": paper.get('publication_year'),\n",
    "            \"cited_by_count\": paper.get('cited_by_count'),\n",
    "            \"reference_count\": paper.get('referenced_works_count'),\n",
    "            \"referenced_works\": \"; \".join(referenced_works),\n",
    "            \"abstract\": abstract,\n",
    "            \"authors\": \"; \".join([a for a in authors_list if a]),\n",
    "            \"institutions\": \"; \".join([i for i in institutions_list if i]),\n",
    "            \"countries\": \"; \".join([c for c in countries_list if c]),\n",
    "            # Updated per OpenAlex API changes to fetch journal info from primary_location.source\n",
    "            \"journal\": paper.get('primary_location', {}).get('source', {}).get('display_name'),\n",
    "            \"journal_issn\": paper.get('primary_location', {}).get('source', {}).get('issn_l'),\n",
    "            \"is_open_access\": paper.get('open_access', {}).get('is_oa'),\n",
    "            \"is_retracted\": paper.get('is_retracted'),\n",
    "            \"concepts\": \"; \".join(concepts)\n",
    "        })\n",
    "\n",
    "    # Convert list of dicts to pandas DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "    # Save DataFrame to CSV without index\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved {len(df)} papers with non-empty abstracts, bibliographies, and valid country data to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    field_name = \"computer science\"  # Choose the research field\n",
    "    max_year = 2025                  # Fetch papers up to this year\n",
    "    min_year = 2025                  # Fetch papers starting from this year (only one year in this example)\n",
    "    max_results = 10000              # Maximum number of papers to retrieve\n",
    "\n",
    "    try:\n",
    "        # Get OpenAlex field concept ID for filtering papers\n",
    "        field_id = get_field_id(field_name)\n",
    "        print(f\"Field '{field_name}' found with ID: {field_id}\")\n",
    "\n",
    "        # Fetch papers metadata from OpenAlex API\n",
    "        papers = fetch_papers_up_to_year(field_id, max_year=max_year, min_year=min_year, max_results=max_results)\n",
    "        print(f\"Fetched {len(papers)} papers (before filtering).\")\n",
    "\n",
    "        # Save filtered and processed papers to CSV file\n",
    "        filename = f\"{field_name.replace(' ', '_')}_up_to_{max_year}_with_bibliography.csv\"\n",
    "        save_papers_to_csv(papers, filename)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77132637-e5d5-435b-bf2f-8b8c3de94e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
